{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Metrics to analyze the model performance\n",
    "    - Confusion Matrix\n",
    "    - Accuracy\n",
    "    - Recall (sensitivity or true positive rate)\n",
    "    - Precision\n",
    "    - Precision - Recall Tradeoff\n",
    "    - F1 Score\n",
    "    - ROC/AUC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix \n",
    "<img src=\"../docs/confusion_matrix.jpg\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Type 1 Error (False Positive Rate) \n",
    "    \n",
    "    - Type 2 Error (False Negative Rate) \n",
    "\n",
    "    - False Positive Rate = FP/ (FP + TN)\n",
    "\n",
    "    - False Negative Rate = FN / (FN + TP)\n",
    "    \n",
    "    - True Positive Rate = TP / (TP + FN)\n",
    "\n",
    "    - Accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "\n",
    "    - Recall = TP / (TP + FN) => True Positive Rate or Sensitivity\n",
    "        - out of actual total positive classes, how many did we predict correctly positively\n",
    "\n",
    "    - Precision = TP / (TP + FP) => Positive Prediction Value\n",
    "        - out of total predicted positive classes, how many were actually positive\n",
    " \n",
    "    - F(beta) Score: When you want to consider both precision and recall equally important \n",
    "        - When FP and FN are equally important then beta = 1\n",
    "        - When FP has more impact then 0.5 <= beta <= 1\n",
    "        - When FN has more impact then beta > 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve - Receiving Optimistic Characteristic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[YouTube Video -> ritvikmath](https://www.youtube.com/watch?v=SHM_GgNI4fY)\n",
    "    - TPR vs FPR Graph\n",
    "    - Never go below the random line\n",
    "    - AUC decides which ROC Curve is better, but it loses information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
